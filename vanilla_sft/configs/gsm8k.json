{
  "epochs": 8,
  "grad_accumulation": 1,
  "gen_length": 512,
  "batch_size": 2,
  "test_batch_size": 2,
  "lr": 1e-05,
  "weight_decay": 0.01,
  "warm_up_ratio": 0.1,
  "warm_up_steps": 100,
  "ckpt_save": "checkpoints/",
  "eval_save": "eval/",
  "log_save": "log/",
  "log_divisor": 100,
  "save_divisor": 0,
  "eval_divisor": 2,
  "min_eval_epoch": 0,
  "max_eval_epoch": 8,
  "exp_name": "gsm8k_3B",
  "task": "gsm8k",
  "optimizer": "Adam",
  "scheduler": "linear",
  "precision": "bf16",
  "model_name": "meta-llama/Llama-3.2-3B",
  "max_length": 512,
  "n_shot": 8,
  "self_consistency": 5
}