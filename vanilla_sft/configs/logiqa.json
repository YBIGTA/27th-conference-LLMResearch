{
  "epochs": 3,
  "grad_accumulation": 4,
  "gen_length": 512,
  "batch_size": 4,
  "test_batch_size": 4,
  "lr": 5e-05,
  "weight_decay": 0.01,
  "warm_up_ratio": 0.1,
  "ckpt_save": "checkpoints/",
  "eval_save": "eval/",
  "log_save": "log/",
  "log_divisor": 100,
  "save_divisor": 0,
  "eval_divisor": 2,
  "exp_name": "logiqa",
  "task": "logiqa",
  "optimizer": "Adam",
  "scheduler": "linear",
  "precision": "bf16",
  "model_name": "meta-llama/Llama-3.2-3B",
  "max_length": 512,
  "n_shot": 0,
  "self_consistency": 5,
  "noise_path": "noise_sentence/real_noise.json",
  "add_noise": "post"

}